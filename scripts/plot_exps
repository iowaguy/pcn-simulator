#!/usr/bin/env python3

import argparse
import os
from os import listdir
from os.path import isdir, realpath, dirname
import sys
from glob import glob
import pprint
import re

script_dir = dirname(realpath(__file__))

# This line is required so I can use the pcn module
sys.path.append(script_dir + '/../')
import pcn


metric_file_mapping = {'success_ratio':{'ylabel':'Success Ratio',
                                        'xlabel':'Time Epochs',
                                        'x_range':[0, 100000],
                                        'y_range':[0.0, 1.0],
                                        'filename': 'cnet-succR.txt'},
                       'transaction_values':{'ylabel':'Successful Transaction Values',
                                             'xlabel':'Time Epochs',
                                             'x_range':[0, 100000],
                                             'filename': 'cnet-totalCreditTransacted.txt'},
                       'transaction_values_cumulative':{'ylabel':'Successful Transaction Values',
                                                        'xlabel':'Time Epochs',
                                                        'x_range':[0, 100000],
                                                        'filename': 'cnet-totalCreditTransacted.txt',
                                                        'cumulative': True}}

# This mapping is required because the names in the file paths are not
# intuitive, but it would be difficult to change them.
attack_name_mapping = {'griefing':'-griefing_success-',
                       'griefing_and_dropping':'-griefing-',
                       'dropping':'-drop_all-'}


def get_list_of_files(metric, sorting, algorithm='all', attack_type=None):
    def sort_key_by_attackers(filepath):
        p = re.compile('.*-selected-([0-9]+)-.*')
        m = p.match(filepath)
        if m:
            return int(m.groups()[0])
        else:
            # If the regex doesn't match, this is the baseline and should show up
            # first.
            return -1

    list_of_files= [glob(exp_base + inode + '/READABLE*/0/C*/')[0]
                    + metric_file_mapping[metric]['filename']
                     for inode in listdir(exp_base)
                     if algorithm == 'all' or algorithm in inode
                     if not attack_type or attack_name_mapping[attack_type] in inode
                     if isdir(exp_base + inode)]

    if sorting == 'attackers':
        list_of_files.sort(key=sort_key_by_attackers)
    elif sorting == 'alphanumeric':
        list_of_files.sort()
    else:
        raise Error("Unsupported sorting key")

    return list_of_files


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--experiment', '--exp', required=False,
                        help='The experiment ID')
    parser.add_argument('--dataset', '--ds', required=False,
                        help='The dataset ID')
    parser.add_argument('--path', required=False,
                        help='The directory to plot')
    parser.add_argument('--algorithm', required=False, default='all',
                        choices=['all', 'speedymurmurs', 'maxflow'],
                        help='The routing algorithm to plot')
    parser.add_argument('--attack_type', required=False, default=None,
                        choices=['griefing', 'griefing_and_dropping', 'dropping'],
                        help='The routing algorithm to plot')    
    parser.add_argument('--basepath', required=False, default=script_dir + '/../data/',
                        help='The path to the experiment data directory')
    parser.add_argument('--metric', required=False, choices=['all', 'success_ratio',
                                                             'transaction_values',
                                                             'transaction_values_cumulative'],
                        default='all', help='The metric to plot')
    # parser.add_argument('--xlabel', required=False, default=None,
    #                     help='The x-axis label')
    # parser.add_argument('--ylabel', required=False, default=None,
    #                     help='The y-axis label')
    parser.add_argument('--sorting', required=False, choices=['alphanumeric',
                                                              'attackers',],
                        default='attackers', help='The key for sorting lines.')
    parser.add_argument('--running_avg', required=False, default=1500,
                        help='The running average of the plot')
    parser.add_argument('--write', action='store_true',
                        default=False, help='Write plots to files')
    parser.add_argument('--legend', nargs='+', required=False, default=[],
                        help='The labels for the legend. The order should correspond'
                        ' to the alphanumeric ordering of the simulation result'
                        ' directories in the experiment directory.')
    args = parser.parse_args()

    if args.experiment and args.dataset:
        slug = f'id{args.dataset}-{args.experiment}'
        exp_output = f"dynamic-{slug}/"
    elif args.path:
        slug = args.path
        exp_output = args.path + "/"

    exp_base = args.basepath + exp_output
    if args.metric == 'all':
        for metric_name, metric_props in metric_file_mapping.items():
            list_of_files = get_list_of_files(metric_name, sorting=args.sorting,
                                              algorithm=args.algorithm,
                                              attack_type=args.attack_type)
    
            pp = pprint.PrettyPrinter(indent=4)
            pp.pprint(list_of_files)
            xlabel = metric_props.get('xlabel', None)
            ylabel = metric_props.get('ylabel', None)

            plot_name = f'{slug}{attack_name_mapping[args.attack_type]}{metric_name}'
            pcn.line_plot_from_list(list_of_files,
                                    xlabel=xlabel,
                                    ylabel=ylabel,
                                    running_avg=args.running_avg,
                                    x_range=metric_props.get('x_range', None),
                                    y_range=metric_props.get('y_range', None),
                                    legend_labels=args.legend,
                                    cumulative=metric_props.get('cumulative', False),
                                    write=args.write, plot_name=plot_name)
